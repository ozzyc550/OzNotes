---
title: 'Action Chunking with Transformers，ACT'
publishDate: '2025-08-12'
updatedDate: '2025-08-12'
description: 'VLA探索之路'
tags:
  - 机器人
language: 'Chinese'
---

# Learning Fine-Grained Bimanual Manipulation with Low-Cost Hardware

> 通过低成本硬件学习精细的双臂操作

## Abstract

精细操作任务（如穿扎带或安装电池）对机器人而言向来极具挑战性，因为这类任务需要精准操作、对接触力的精细协调以及闭环视觉反馈。执行这些任务通常需要高端机器人，精确的传感器或细致的校准，而这些往往成本高昂且设置复杂。

**学习能否让低成本、低精度的硬件也能够完成这些精细的操作任务？**

我们提出了一种低成本系统，通过定制的遥操接口采集真机演示数据，并直接进行端到端的模仿学习。然而，**模仿学习**本身也存在挑战，尤其是在高精度领域：系统中的误差会随着时间累积，而人类演示可能是不平稳的。为了应对这些挑战，我们开发了一种简单而新颖的算法——**基于 Transformer 的动作分块（Action Chunking with Transformers，ACT）**，该算法学习了一个动作序列的生成模型。ACT 让机器人仅凭 10 分钟的演示，就能学习现实世界中的 6 项困难任务（例如以 80% 至 90% 的成功率打开半透明调味杯和安装电池）。

> 项目地址：[https://tonyzhaozh.github.io/aloha](https://tonyzhaozh.github.io/aloha)

## Introduction

精细操作任务涉及精确的闭环反馈，并需要高度的手眼协调能力，以便根据环境变化进行调整和重新规划。此类操作任务（例如打开调味杯盖或插入电池）涉及捏、撬、撕等精细动作，而非抓取和放置等大幅度动作。

以打开调味杯盖为例，杯子最初是直立放置在桌面上的：右侧夹爪首先需要将杯子倾斜，然后将其推入已张开的左侧夹爪中。随后左侧夹爪轻轻闭合，并将杯子从桌面上取下。接下来，其中一个右侧手指从下方靠近并撬开杯盖。上述每一步都需要极高的精度、细致的手眼协调和成熟的控制。任何毫米级的误差都可能导致任务失败。

![20250812104021-2025-08-12-10-40-21](https://ozzyc.oss-cn-shenzhen.aliyuncs.com/NotePicture/20250812104021-2025-08-12-10-40-21.png)

现有的精细操作系统采用昂贵的机器人和高端传感器进行精确状态估计。在本研究中，我们致力于开发一种低成本的精细操作系统，使其更容易获取且可重复实现。然而，低成本硬件必然不如高端平台精度高，这使得感知和规划的挑战更加突出。

解决这一问题的一个有前景的方向是将 **学习（Learning）** 融入系统。人类也不具备工业级的本体感知，但我们能够通过从闭环视觉反馈中学习，并主动补偿误差来执行精细任务。**因此，我们训练了一个端到端的策略，将普通网络摄像头捕捉到的 RGB 图像直接映射到相应的动作上。**

这种“像素到动作”的模式尤其适合精细操作，因为精细操作通常涉及具有复杂物理属性的物体，此时学习操作策略比建模整个环境要简单得多。以调味杯为例：建模轻推杯子时的接触以及撬开杯盖时的变形过程，涉及大量自由度下的复杂物理计算。设计一个足够精确以用于规划的模型需要大量的研究和针对特定任务的工程代价。相比之下，轻推和打开杯子的策略要简单得多，因为闭环策略可以对杯体和杯盖的不同位置做出反应，而无需提前精确预测它们将如何移动。

然而，训练一个端到端策略也有其自身的挑战，其表现很大程度上取决于训练数据的分布。对于精细操作，高质量的人类示范可以让系统学习人类的灵活性，从而创造巨大价值。因此，我们构建了一个低成本但灵活的遥操系统用于数据收集，并设计了一种新颖的能从示范中有效学习的模仿学习算法。

### 遥操系统

我们设计了一种遥操装置，使用了两套低成本的量产机械臂。它们结构相似但尺寸不同，我们采用关节空间映射进行遥操作。我们还通过增加 3D 打印件实现了更便捷的反向驱动，从而在 2 万美元的预算内打造出了一个功能强大的遥操系统。我们在 Fig. 1 中展示了其能力，包括对精细任务（如穿扎带）、动态任务（如抛接乒乓球）以及高接触度任务（如组装 NIST 板上的链条）。

![20250812115705-2025-08-12-11-57-05](https://ozzyc.oss-cn-shenzhen.aliyuncs.com/NotePicture/20250812115705-2025-08-12-11-57-05.png)

> Fig. 1：ALOHA：一种低成本开源的双臂遥操硬件系统。整个系统成本低于 2 万美元，采用量产机器人和 3D 打印件。左图：用户通过反向驱动领导机器人进行遥操，跟随机器人同步其动作。右图：ALOHA 系统能执行精细任务、高接触度任务和动态任务。我们展示了遥操和学习的示例。

### 模仿学习算法

即使演示质量很高，那些需要精准度和视觉反馈的任务对模仿学习来说也是一项艰巨的挑战。预测动作中的微小误差可能导致状态出现显著不同，从而加剧模仿学习中的“误差累积”问题。

为了解决这个问题，我们借鉴了心理学中的 **“动作分块”（action chunking）概念**，该概念描述了动作序列如何被分组为一个块，并作为一个单元执行。我们的算法会预测接下来 $k$ 个时间步的目标关节位置，而不是一次只预测一步。这将任务的有效时间范围缩短为原来的 $\frac{1}{k}$，从而减轻了累积误差。预测动作序列还有助于解决了时间相关的干扰因素，例如演示中的停顿，这些停顿很难用马尔可夫单步策略建模。为了进一步提高策略的平滑性，我们提出了**时序集成（temporal ensembling）**。通过以更高的频率查询策略，并对重叠的动作块进行平均。

我们采用专为序列建模设计的 Transformer 架构，以实现动作分块策略，并将其作为**条件变分自编码器（Conditional VAE, CVAE）** 训练，以捕捉人类演示数据中的变异性。我们将该方法命名为 **基于 Transformer 的动作分块（Action Chunking with Transformers，ACT）**。实验表明，在一系列仿真和真实环境的精细操作任务中，ACT 显著优于以往的模仿学习算法。

本文的关键贡献是一个低成本的精细操作学习系统，该系统包括一个遥操系统和一种新颖的模仿学习算法。尽管遥操系统成本低廉，但它却能够执行高精度和多交互的任务。模仿学习算法——基于 Transformer 的动作分块（ACT）能够学习精确的闭环行为，其性能远超以往方法。两者的协同配合使得系统能够直接在真实世界中学习 6 种精细操作技能。例如打开半透明调料杯、插入电池等，仅需 10 分钟或 50 条演示轨迹即可达到 80-90% 的成功率。

## Related Work

### 机器人操作中的模仿学习

模仿学习使得机器人能够直接从专家那里学习。行为克隆（BC）是最简单的模仿学习算法之一，它将模仿视为从观察到动作的监督学习。之后的许多研究试图改进 BC，例如将历史记录与各种架构相结合、使用不同的训练目标以及加入正则化。其他研究工作则侧重于模仿学习的多任务或少样本方面，主要研究语言或特定任务结构。通过使用更多数据来扩展这些模仿学习算法，已经催生出了能泛化到新物体、指令或场景的令人印象深刻的系统。

本研究专注于构建一个低成本且能够执行精细操作任务的模仿学习系统。我们从软硬件两个方面入手，通过构建一个高性能的遥操系统和一种新型的模仿学习算法，使得在精细操作任务上相较以往方法取得了显著提升。

### 处理累积误差

BC 的主要缺点是累积误差，即前一时间步的误差会累积并导致机器人偏离其训练分布，从而进入难以恢复的状态。这个问题在精细操作场景中尤为突出。缓解累积误差的一种方法是允许额外的策略交互和专家修正，例如 DAgger 及其变体。然而，使用遥操接口进行专家标注是耗时且不自然的。也可以在演示收集时注入噪声，以获得包含纠正行为的数据集。但对于精细操作，噪声注入可能会直接导致任务失败，从而降低遥操系统的灵活性。

为了避免这些问题，之前的研究通过离线方式生成合成的修正数据。然而它们仅限于低维状态可用的场景，或特定类型的任务（如抓取）。由于这些限制，我们需要从不同角度解决累积误差问题，以适应高维视觉观测。我们提出通过动作分块（action chunking）来缩短任务的有效时域，即预测动作序列而非单一动作，然后通过集成重叠的动作块来生成既准确又平滑的轨迹。

### 双臂操作

双臂操作在机器人领域有着悠久的历史，并随着硬件成本的降低变得越来越流行。早期的研究利用环境动力学从经典控制的角度处理双手操作问题，但设计这种模型耗时较长，且对于具有复杂物理特性的物体可能不够准确。近年来，学习机制已被引入到双臂系统中，例如强化学习、模仿人类演示，或学习预测串联运动原语的关键点。其中一些研究也专注于精细操作任务，如解开绳结、平整布料，甚至穿针，使用的是价格相对较高的机器人，例如 da Vinci 手术机器人或 ABB YuMi。

我们的工作聚焦于低成本硬件，例如每台成本约为 5 千美元的机械臂，并力求使其能够执行高精度、闭环控制的任务。我们的遥操系统与 Kim 等人的研究最为相似，同样采用领导者与跟随者之间的关节空间映射。与先前的系统不同，我们并未使用特殊的编码器、传感器或加工部件，仅使用量产机器人和少量 3D 打印部件构建系统，让非专业人员可在 2 小时内完成组装。